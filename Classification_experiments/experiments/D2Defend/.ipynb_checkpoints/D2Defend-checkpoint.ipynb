{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yJIXQi44dDw"
   },
   "source": [
    "# D2Defend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBVovCqgESy9",
    "outputId": "38a310eb-ef4c-425d-9066-0eb3c1c76466"
   },
   "outputs": [],
   "source": [
    "!pip install pywavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T11:19:52.653545Z",
     "iopub.status.busy": "2024-12-06T11:19:52.652870Z",
     "iopub.status.idle": "2024-12-06T11:19:57.615106Z",
     "shell.execute_reply": "2024-12-06T11:19:57.614083Z",
     "shell.execute_reply.started": "2024-12-06T11:19:52.653503Z"
    },
    "id": "QtMoPyNn4dD0"
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import logging\n",
    "from typing import Tuple, List\n",
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from skimage.restoration import denoise_wavelet\n",
    "import zipfile\n",
    "import pywt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nMJpTI14dD4"
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T11:20:00.975928Z",
     "iopub.status.busy": "2024-12-06T11:20:00.975613Z",
     "iopub.status.idle": "2024-12-06T11:20:00.992743Z",
     "shell.execute_reply": "2024-12-06T11:20:00.991979Z",
     "shell.execute_reply.started": "2024-12-06T11:20:00.975900Z"
    },
    "id": "C2N_NGWz4dD4"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Bilateral Filtering Code\n",
    "\n",
    "def bilateral_filter(image, device, sigma_r=75, sigma_s=75):\n",
    "    \"\"\"\n",
    "    Apply bilateral filtering to an image.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor of shape (C, H, W).\n",
    "        device (torch.device): Device for computation (CPU/GPU).\n",
    "        sigma_r (float): Sigma value for color space.\n",
    "        sigma_s (float): Sigma value for coordinate space.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Bilateral filtered image tensor of shape (C, H, W).\n",
    "    \"\"\"\n",
    "    assert isinstance(image, torch.Tensor), \"Input must be a PyTorch tensor.\"\n",
    "    assert len(image.shape) == 3, \"Expected shape (C, H, W) for a single image.\"\n",
    "\n",
    "    # Convert PyTorch tensor to NumPy array (HWC) scaled to 0-255\n",
    "    image_np = image.permute(1, 2, 0).cpu().numpy() * 255.0\n",
    "    image_np = np.clip(image_np, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Apply bilateral filter\n",
    "    filtered_np = cv2.bilateralFilter(image_np, d=9, sigmaColor=sigma_r, sigmaSpace=sigma_s)\n",
    "\n",
    "    # Convert back to PyTorch tensor (C, H, W) scaled to 0-1\n",
    "    filtered_tensor = torch.from_numpy(filtered_np.astype(np.float32) / 255.0).permute(2, 0, 1).to(device)\n",
    "    return filtered_tensor\n",
    "\n",
    "def wavelet_shrinkage_color_image(image, device, method='BayesShrink', sigma=None):\n",
    "    \"\"\"\n",
    "    Apply wavelet shrinkage to denoise a color image.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor of shape (C, H, W).\n",
    "        device (torch.device): Device for computation (CPU/GPU).\n",
    "        method (str): Method for wavelet shrinkage ('BayesShrink' or 'VisuShrink').\n",
    "        sigma (float): Noise standard deviation.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Denoised image tensor of shape (C, H, W).\n",
    "    \"\"\"\n",
    "    # Move the tensor to CPU\n",
    "    noisy_image = image.cpu().detach().numpy()\n",
    "\n",
    "    denoised_image = np.zeros_like(noisy_image)\n",
    "\n",
    "    for i in range(noisy_image.shape[2]):  # Iterate over each channel (R, G, B)\n",
    "        denoised_image[..., i] = denoise_wavelet(\n",
    "            noisy_image[..., i],\n",
    "            method=method,\n",
    "            mode='soft',\n",
    "            sigma=sigma,\n",
    "            rescale_sigma=True,\n",
    "            channel_axis=None\n",
    "        )\n",
    "\n",
    "    # Convert back to PyTorch tensor and move to the specified device\n",
    "    denoised_image = torch.tensor(denoised_image).to(device)\n",
    "    return denoised_image\n",
    "\n",
    "\n",
    "# D2Defend Model\n",
    "class D2Defend(nn.Module):\n",
    "    \"\"\"\n",
    "    D2Defend: A robust image classification model with advanced denoising techniques.\n",
    "\n",
    "    Key Features:\n",
    "    - Bilateral filtering for edge preservation\n",
    "    - Short-time Fourier transform for texture analysis\n",
    "    - Wavelet shrinkage for noise reduction\n",
    "    - Multi-stage convolutional classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_r, sigma_s, lambda_val, num_classes, device):\n",
    "        \"\"\"\n",
    "        Initialize D2Defend model components.\n",
    "\n",
    "        Args:\n",
    "            sigma_r (float): Color space sigma for bilateral filtering\n",
    "            sigma_s (float): Coordinate space sigma for bilateral filtering\n",
    "            lambda_val (float): Regularization parameter\n",
    "            num_classes (int): Number of output classification categories\n",
    "            device (torch.device): Computational device\n",
    "        \"\"\"\n",
    "        super(D2Defend, self).__init__()\n",
    "        self.sigma_r = sigma_r\n",
    "        self.sigma_s = sigma_s\n",
    "        self.lambda_val = lambda_val\n",
    "        self.device = device\n",
    "\n",
    "        # Bilateral filtering layer\n",
    "        self.bilateral_filter = bilateral_filter\n",
    "\n",
    "\n",
    "        # Short-time Fourier transform layer\n",
    "        self.stft = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(3, 3, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Wavelet shrinkage layer\n",
    "        self.wavelet_shrinkage = wavelet_shrinkage_color_image\n",
    "\n",
    "        # Inverse short-time Fourier transform layer\n",
    "\n",
    "        self.istft = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(3, 3, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Classification layer\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 128),  # Fully connected layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the D2Defend model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input image tensor\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Classification output\n",
    "        \"\"\"\n",
    "        if len(x.shape) == 4:\n",
    "            filtered_images = []\n",
    "            for img in x:  # Loop through each image in the batch\n",
    "                filtered_images.append(self.bilateral_filter(img, self.device,self.sigma_r, self.sigma_s))\n",
    "            x_edge = torch.stack(filtered_images).to(self.device)  # Combine filtered images back into a batch\n",
    "        elif len(x.shape) == 3:  # Single image\n",
    "            x_edge = self.bilateral_filter(x, self.sigma_r, self.sigma_s, self.device).to(self.device)  # Move to same device as x\n",
    "\n",
    "        # Short-time Fourier transform\n",
    "        x_texture =(x - x_edge).to(self.device)\n",
    "\n",
    "        x_edge = x_edge.to(self.device)\n",
    "        x_texture_stft = self.stft(x_texture)\n",
    "\n",
    "        # Wavelet shrinkage\n",
    "        x_texture_shrinkage = self.wavelet_shrinkage(x_texture_stft, device=self.device, method='BayesShrink', sigma=None)\n",
    "\n",
    "        # Inverse short-time Fourier transform\n",
    "        x_texture_istft = self.istft(x_texture_shrinkage).to(self.device)\n",
    "\n",
    "        # Combine edge and texture layers\n",
    "        x_texture_istft = x_texture_istft.to(self.device)\n",
    "        x_defend = x_edge + x_texture_istft\n",
    "        print(x_defend.shape)\n",
    "        # Classification\n",
    "        features = self.classifier(x_defend)\n",
    "        features = features.view(features.size(0), -1).to(self.device)  # Flatten for fully connected layer\n",
    "        output = self.fc(features)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpcKcN2l4dD6"
   },
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T11:20:02.279198Z",
     "iopub.status.busy": "2024-12-06T11:20:02.278337Z",
     "iopub.status.idle": "2024-12-06T11:20:02.305423Z",
     "shell.execute_reply": "2024-12-06T11:20:02.304606Z",
     "shell.execute_reply.started": "2024-12-06T11:20:02.279164Z"
    },
    "id": "60V7w5JT4dD6"
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "sigma_r = 75\n",
    "sigma_s = 75\n",
    "lambda_val = 1\n",
    "num_epochs = 20\n",
    "early_stop_patience = 5\n",
    "early_stop_counter = 0\n",
    "best_loss = float('inf')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = D2Defend(sigma_r, sigma_s, lambda_val, num_classes=2, device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5RbjuH14dD6"
   },
   "source": [
    "# Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSJZVF2S4dD7"
   },
   "outputs": [],
   "source": [
    "# Unzipping custom_dataset.zip\n",
    "#The unzipping results in 2 datasets - custom_dataset and test_dataset - being created in the working directory\n",
    "with zipfile.ZipFile(\"corrected_dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('custom_dataset')\n",
    "\n",
    "# Unzipping tes-final.zip\n",
    "with zipfile.ZipFile(\"test_dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-06T11:21:57.724901Z",
     "iopub.status.busy": "2024-12-06T11:21:57.724167Z",
     "iopub.status.idle": "2024-12-06T11:28:07.094885Z",
     "shell.execute_reply": "2024-12-06T11:28:07.093594Z",
     "shell.execute_reply.started": "2024-12-06T11:21:57.724866Z"
    },
    "id": "O63cAhTF4dD7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fe3d4dec-f0b7-4194-be5a-0e212a64337c"
   },
   "outputs": [],
   "source": [
    "# Define transforms for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# loading dataset\n",
    "test_path = 'custom_dataset/test'\n",
    "train_path = 'custom_dataset/train'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "\n",
    "# Split training dataset into 80% for training and 20% for validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define early stopping criterion\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001): # Change _init_ to __init__\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = np.inf\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, loss): # Change _call_ to __call__\n",
    "        if loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Define model, optimizer, and criterion\n",
    "model = D2Defend(sigma_r, sigma_s, lambda_val, num_classes=2, device=device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define early stopping and best/final weights saving\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "best_weights = None\n",
    "final_weights = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        clean_output = model(data)\n",
    "        clean_loss = criterion(clean_output, target)\n",
    "        clean_loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_train_loss += clean_loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(val_loader, desc=\"Validation\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_val_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping and best/final weights saving\n",
    "    if early_stopping(avg_val_loss):\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "    if avg_val_loss < early_stopping.best_loss:\n",
    "        best_weights = model.state_dict()\n",
    "    final_weights = model.state_dict()\n",
    "\n",
    "# Make inferences on test dataset\n",
    "model.load_state_dict(final_weights)\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader, desc=\"Test\"):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJGFnOcQ4dD-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6243365,
     "sourceId": 10118735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
