{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoXL0qPk1YlK"
   },
   "source": [
    "\n",
    "\n",
    "# Image Classification with Dual Path Network (DPN)\n",
    "\n",
    "**Training, Validation, and Testing with Dual Path Network (DPN) Model on Custom Dataset for Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFnzmSIG1y28"
   },
   "source": [
    "## Intializing and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cflrNXB1PzEy"
   },
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install tqdm\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install scikit-image\n",
    "!pip install scikit-learn\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:21:54.733447Z",
     "iopub.status.busy": "2024-12-05T16:21:54.733016Z",
     "iopub.status.idle": "2024-12-05T16:21:59.061770Z",
     "shell.execute_reply": "2024-12-05T16:21:59.061074Z",
     "shell.execute_reply.started": "2024-12-05T16:21:54.733408Z"
    },
    "id": "BxDk6LxE1WWF"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms as T\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import random_split\n",
    "import shutil\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imghdr  # For detecting image file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:21:59.532020Z",
     "iopub.status.busy": "2024-12-05T16:21:59.531791Z",
     "iopub.status.idle": "2024-12-05T16:21:59.539394Z",
     "shell.execute_reply": "2024-12-05T16:21:59.538529Z",
     "shell.execute_reply.started": "2024-12-05T16:21:59.531997Z"
    },
    "id": "HCDiwnMa1WWH"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "learning_rate = 1e-3\n",
    "num_classes = 2  # two classes: Real and Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:21:59.540695Z",
     "iopub.status.busy": "2024-12-05T16:21:59.540456Z",
     "iopub.status.idle": "2024-12-05T16:21:59.628235Z",
     "shell.execute_reply": "2024-12-05T16:21:59.627329Z",
     "shell.execute_reply.started": "2024-12-05T16:21:59.540670Z"
    },
    "id": "OuTKV7I91WWH"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JRI93SU2Kik"
   },
   "source": [
    "## Custom Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUWACfzR6Qro"
   },
   "source": [
    "### Custom Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:21:59.629868Z",
     "iopub.status.busy": "2024-12-05T16:21:59.629553Z",
     "iopub.status.idle": "2024-12-05T16:21:59.640372Z",
     "shell.execute_reply": "2024-12-05T16:21:59.639580Z",
     "shell.execute_reply.started": "2024-12-05T16:21:59.629839Z"
    },
    "id": "SfHUgmms1WWH"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset with LBP preprocessing\n",
    "class LBPImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for applying Local Binary Patterns (LBP) preprocessing to images.\n",
    "\n",
    "    Args:\n",
    "        root (str): Path to the root directory of the dataset.\n",
    "        transform (callable, optional): Optional transformations to apply to the images.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the LBPImageDataset.\n",
    "\n",
    "        Args:\n",
    "            root (str): Root directory for the dataset.\n",
    "            transform (callable, optional): Transformations to apply to the preprocessed images.\n",
    "        \"\"\"\n",
    "        self.dataset = ImageFolder(root=root)\n",
    "        self.transform = transform\n",
    "\n",
    "    def lbp_preprocessing(self, image):\n",
    "        \"\"\"\n",
    "        Applies LBP preprocessing, FFT, and combines the results with the original image.\n",
    "\n",
    "        Steps:\n",
    "        1. Resize the image to (384, 384).\n",
    "        2. Convert to 3-channel RGB if grayscale or remove the alpha channel if present.\n",
    "        3. Compute the grayscale version of the image.\n",
    "        4. Compute the Local Binary Pattern (LBP) on the grayscale image.\n",
    "        5. Compute the FFT of the grayscale image.\n",
    "        6. Concatenate the original RGB image, LBP, and FFT channels.\n",
    "\n",
    "        Args:\n",
    "            image (numpy.ndarray): Input image as a NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Preprocessed image with concatenated RGB, LBP, and FFT channels.\n",
    "        \"\"\"\n",
    "        image = resize(image, (384, 384), anti_aliasing=True)\n",
    "        if image.ndim == 2:\n",
    "            image = np.stack([image] * 3, axis=-1)\n",
    "        elif image.shape[2] == 4:\n",
    "            image = image[:, :, :3]\n",
    "        image_rgb = image.astype(\"float32\")\n",
    "\n",
    "        image_gray = rgb2gray(image_rgb)\n",
    "        P, R = 8, 1\n",
    "        lbp = local_binary_pattern(image_gray, P, R, method=\"uniform\")\n",
    "        fft = np.log(np.abs(np.fft.fft2(image_gray)) + 1)\n",
    "\n",
    "        lbp_expanded = np.expand_dims(lbp, axis=-1)\n",
    "        fft_expanded = np.expand_dims(fft, axis=-1)\n",
    "        concatenated = np.concatenate((image_rgb, lbp_expanded, fft_expanded), axis=-1)\n",
    "        concatenated = nn.Conv2d(in_channels=5, out_channels=3, kernel_size=1, padding=0)\n",
    "\n",
    "        return concatenated.astype(\"float32\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves an image and its corresponding label at the specified index,\n",
    "        applies LBP preprocessing, and optionally applies additional transformations.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the preprocessed image and its label.\n",
    "        \"\"\"\n",
    "        image, label = self.dataset[idx]\n",
    "        image_np = np.array(image)  # Convert PIL image to NumPy\n",
    "        processed_image = self.lbp_preprocessing(image_np)\n",
    "        if self.transform:\n",
    "            processed_image = self.transform(processed_image)\n",
    "        return processed_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:21:59.641639Z",
     "iopub.status.busy": "2024-12-05T16:21:59.641368Z",
     "iopub.status.idle": "2024-12-05T16:21:59.653841Z",
     "shell.execute_reply": "2024-12-05T16:21:59.652970Z",
     "shell.execute_reply.started": "2024-12-05T16:21:59.641614Z"
    },
    "id": "ae7D0q5T1WWH"
   },
   "outputs": [],
   "source": [
    "class DoubleLayerGaussianFilter(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch module that applies a double layer Gaussian filter to an input tensor.\n",
    "\n",
    "    Args:\n",
    "        channels (int): Number of input channels.\n",
    "        kernel_size (int, optional): Size of the Gaussian kernel. Default is 3.\n",
    "        sigma (float, optional): Standard deviation for the Gaussian kernel. Default is 1.0.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, kernel_size=3, sigma=1.0):\n",
    "        \"\"\"\n",
    "        Initializes the DoubleLayerGaussianFilter.\n",
    "\n",
    "        Args:\n",
    "            channels (int): Number of input channels.\n",
    "            kernel_size (int, optional): Kernel size for the Gaussian filter. Default is 3.\n",
    "            sigma (float, optional): Standard deviation of the Gaussian filter. Default is 1.0.\n",
    "        \"\"\"\n",
    "        super(DoubleLayerGaussianFilter, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.gaussian_filter = self.create_gaussian_filter()\n",
    "\n",
    "    def create_gaussian_filter(self):\n",
    "        \"\"\"\n",
    "        Creates a Gaussian filter kernel.\n",
    "\n",
    "        Returns:\n",
    "            nn.Parameter: A normalized Gaussian kernel with shape\n",
    "                          (channels, 1, kernel_size, kernel_size).\n",
    "        \"\"\"\n",
    "        k = self.kernel_size // 2\n",
    "        x = torch.arange(-k, k + 1, dtype=torch.float32)\n",
    "        y = torch.arange(-k, k + 1, dtype=torch.float32)\n",
    "        xx, yy = torch.meshgrid(x, y)\n",
    "        kernel = torch.exp(-(xx**2 + yy**2) / (2 * self.sigma**2))\n",
    "        kernel /= kernel.sum()  # Normalize kernel\n",
    "        kernel = kernel.expand(self.channels, 1, -1, -1)\n",
    "        return nn.Parameter(kernel, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Applies the double layer Gaussian filter to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Filtered tensor after applying the Gaussian filter twice.\n",
    "        \"\"\"\n",
    "        padding = self.kernel_size // 2\n",
    "        x = nn.functional.conv2d(x, self.gaussian_filter, padding=padding, groups=self.channels)\n",
    "        x = nn.functional.conv2d(x, self.gaussian_filter, padding=padding, groups=self.channels)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AddGaussianNoise:\n",
    "    \"\"\"\n",
    "    A transformation class that adds Gaussian noise to a tensor.\n",
    "\n",
    "    Args:\n",
    "        mean (float, optional): Mean of the Gaussian noise. Default is 0.\n",
    "        std (float, optional): Standard deviation of the Gaussian noise. Default is 0.1.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the AddGaussianNoise transformation.\n",
    "\n",
    "        Args:\n",
    "            mean (float, optional): Mean of the Gaussian noise. Default is 0.\n",
    "            std (float, optional): Standard deviation of the Gaussian noise. Default is 0.1.\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Adds Gaussian noise to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            tensor (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor with added Gaussian noise.\n",
    "        \"\"\"\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:21:59.655740Z",
     "iopub.status.busy": "2024-12-05T16:21:59.655227Z",
     "iopub.status.idle": "2024-12-05T16:21:59.666304Z",
     "shell.execute_reply": "2024-12-05T16:21:59.665401Z",
     "shell.execute_reply.started": "2024-12-05T16:21:59.655710Z"
    },
    "id": "wHdPxZWy1WWH"
   },
   "outputs": [],
   "source": [
    "class ApplyDoubleGaussianFilter:\n",
    "    \"\"\"\n",
    "    A transformation class that applies a double-layer Gaussian filter to a tensor.\n",
    "\n",
    "    Args:\n",
    "        kernel_size (int or float, optional): Size of the Gaussian kernel. Default is 3.0.\n",
    "        sigma (float, optional): Standard deviation for the Gaussian kernel. Default is 1.0.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=3.0, sigma=1.0):\n",
    "        \"\"\"\n",
    "        Initializes the ApplyDoubleGaussianFilter transformation.\n",
    "\n",
    "        Args:\n",
    "            kernel_size (int or float, optional): Kernel size for the Gaussian filter. Default is 3.0.\n",
    "            sigma (float, optional): Standard deviation of the Gaussian filter. Default is 1.0.\n",
    "        \"\"\"\n",
    "        self.filter = DoubleLayerGaussianFilter(channels=3, kernel_size=kernel_size, sigma=sigma)\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Applies the double-layer Gaussian filter to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            tensor (torch.Tensor): Input tensor of shape (channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor after applying the Gaussian filter.\n",
    "        \"\"\"\n",
    "        # Add batch dimension for processing\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        # Apply filter\n",
    "        filtered = self.filter(tensor)\n",
    "        # Remove batch dimension\n",
    "        return filtered.squeeze(0)\n",
    "\n",
    "\n",
    "class AddCustomNoise:\n",
    "    \"\"\"\n",
    "    A transformation class that adds custom Gaussian noise to a tensor.\n",
    "\n",
    "    Args:\n",
    "        noise_level (float, optional): Standard deviation of the Gaussian noise. Default is 0.1.\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_level=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the AddCustomNoise transformation.\n",
    "\n",
    "        Args:\n",
    "            noise_level (float, optional): Level of Gaussian noise to add. Default is 0.1.\n",
    "        \"\"\"\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Adds Gaussian noise to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            tensor (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor with added Gaussian noise.\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(tensor) * self.noise_level\n",
    "        return tensor + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4dk3YXy6U2d"
   },
   "source": [
    "### Data Augmentation and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:21:59.667681Z",
     "iopub.status.busy": "2024-12-05T16:21:59.667384Z",
     "iopub.status.idle": "2024-12-05T16:21:59.777706Z",
     "shell.execute_reply": "2024-12-05T16:21:59.776878Z",
     "shell.execute_reply.started": "2024-12-05T16:21:59.667654Z"
    },
    "id": "SB8gy9mM1WWH"
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize((224, 224)),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    T.RandomApply([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        # T.RandomRotation(degrees=30),\n",
    "        T.RandomAffine(degrees=0, scale=(0.8, 1.2)),\n",
    "    ], p=0.3),\n",
    "    T.RandomApply([\n",
    "        ApplyDoubleGaussianFilter(kernel_size=3, sigma=1.0),\n",
    "        AddCustomNoise(noise_level=0.1)\n",
    "    ], p=0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KvuRawS3OcH"
   },
   "source": [
    "## Data Preparation and Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27-sotEA6YYN"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jY7aFEyPI2r8"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the zip file path and the destination directory\n",
    "zip_file_path = 'corrected_dataset.zip'\n",
    "extract_dir = 'custom_dataset'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"File extracted to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:22:00.201394Z",
     "iopub.status.busy": "2024-12-05T16:22:00.201107Z",
     "iopub.status.idle": "2024-12-05T16:23:17.776430Z",
     "shell.execute_reply": "2024-12-05T16:23:17.775132Z",
     "shell.execute_reply.started": "2024-12-05T16:22:00.201369Z"
    },
    "id": "CYznHYpr1WWI"
   },
   "outputs": [],
   "source": [
    "full_train_dataset = datasets.ImageFolder(root=\"custom_dataset/train\", transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=\"custom_dataset/test\", transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypdNVwn46bdG"
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:49:05.455076Z",
     "iopub.status.busy": "2024-12-05T16:49:05.454724Z",
     "iopub.status.idle": "2024-12-05T16:49:05.789649Z",
     "shell.execute_reply": "2024-12-05T16:49:05.788575Z",
     "shell.execute_reply.started": "2024-12-05T16:49:05.455047Z"
    },
    "id": "fIWLPlPb1WWI"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = timm.create_model('dpn68b.mx_in1k', pretrained=True, num_classes=num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B1c49034I04"
   },
   "source": [
    "## Model Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo-OuE4J6pmB"
   },
   "source": [
    "### Early stopping implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:49:02.458198Z",
     "iopub.status.busy": "2024-12-05T16:49:02.457243Z",
     "iopub.status.idle": "2024-12-05T16:49:02.464085Z",
     "shell.execute_reply": "2024-12-05T16:49:02.463026Z",
     "shell.execute_reply.started": "2024-12-05T16:49:02.458158Z"
    },
    "id": "WMvD_oMd1WWI"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Implements early stopping to terminate training when validation loss stops improving.\n",
    "\n",
    "    Args:\n",
    "        patience (int, optional): Number of epochs to wait after the last improvement in validation loss.\n",
    "            Training stops if no improvement is observed for 'patience' consecutive epochs. Default is 3.\n",
    "        delta (float, optional): Minimum change in validation loss to qualify as an improvement. Default is 0.0.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, delta=0.0):\n",
    "        \"\"\"\n",
    "        Initializes the EarlyStopping mechanism.\n",
    "\n",
    "        Args:\n",
    "            patience (int, optional): Number of epochs to wait before stopping. Default is 3.\n",
    "            delta (float, optional): Minimum improvement in validation loss to reset the patience counter. Default is 0.0.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Checks if training should stop based on validation loss.\n",
    "\n",
    "        Args:\n",
    "            val_loss (float): Current validation loss.\n",
    "            model (torch.nn.Module): The model being trained. Typically used for saving the best model.\n",
    "\n",
    "        Updates:\n",
    "            self.early_stop (bool): Set to True if training should stop.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRA1driV6syE"
   },
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:49:15.621083Z",
     "iopub.status.busy": "2024-12-05T16:49:15.620386Z",
     "iopub.status.idle": "2024-12-05T16:49:15.628612Z",
     "shell.execute_reply": "2024-12-05T16:49:15.627795Z",
     "shell.execute_reply.started": "2024-12-05T16:49:15.621054Z"
    },
    "id": "5DlMlVmM1WWI"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=1e-4)  # Reduce LR by 0.1 every 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrPSX1fY6vo_"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:23:35.870448Z",
     "iopub.status.busy": "2024-12-05T17:23:35.870061Z",
     "iopub.status.idle": "2024-12-05T17:23:35.883219Z",
     "shell.execute_reply": "2024-12-05T17:23:35.882321Z",
     "shell.execute_reply.started": "2024-12-05T17:23:35.870418Z"
    },
    "id": "5vbpj_LF1WWI"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    early_stopping = EarlyStopping(patience=5, delta=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "\n",
    "            # Ensure tensors and model are on the same device\n",
    "            assert images.device == labels.device == next(model.parameters()).device, \\\n",
    "                \"Tensors and model are not on the same device.\"\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            features = model.forward_features(images)  # Extract features\n",
    "            outputs = model.forward_head(features, pre_logits=False)  # Get logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss/len(train_loader):.3f}, Train Acc: {train_acc:.3f}\")\n",
    "\n",
    "        # Validation\n",
    "        val_acc, precision, recall, f1, cm, all_labels, all_preds, results_df = evaluate_model(model, val_loader, device)\n",
    "        val_loss = train_loss / len(val_loader)  # Use this for early stopping monitoring\n",
    "\n",
    "        print(f\"Validation Acc: {val_acc:.3f}, F1: {f1:.3f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "\n",
    "        # Save the best model based on accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "            # Save the results CSV\n",
    "            results_csv_path = \"Validation_Results.csv\"\n",
    "            results_df.to_csv(results_csv_path, index=False)\n",
    "            print(f\"Validation results saved to {results_csv_path}\")\n",
    "\n",
    "            torch.save(model.state_dict(), \"dpn68b.mx_in1k.pth\")\n",
    "            print(\"Best model saved!\")\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        print(f\"Learning Rate after Epoch {epoch+1}: {scheduler.get_last_lr()}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(model, data_loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)  # Get the class predictions\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame({\n",
    "        \"True Labels\": all_labels,\n",
    "        \"Predicted Labels\": all_preds\n",
    "    })\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "    precision = precision_score(all_labels, all_preds, average=\"binary\", zero_division=1)\n",
    "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return accuracy, precision, recall, f1, cm, all_labels, all_preds, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:23:41.735855Z",
     "iopub.status.busy": "2024-12-05T17:23:41.735517Z",
     "iopub.status.idle": "2024-12-05T20:20:50.312597Z",
     "shell.execute_reply": "2024-12-05T20:20:50.311605Z",
     "shell.execute_reply.started": "2024-12-05T17:23:41.735824Z"
    },
    "id": "2fgZwqSU1WWJ"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "train_model(model, train_loader, val_loader, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xL3JZDR4N7t"
   },
   "source": [
    "### Validate the Model and Generate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T20:47:14.970430Z",
     "iopub.status.busy": "2024-12-05T20:47:14.969603Z",
     "iopub.status.idle": "2024-12-05T20:49:18.963917Z",
     "shell.execute_reply": "2024-12-05T20:49:18.962911Z",
     "shell.execute_reply.started": "2024-12-05T20:47:14.970392Z"
    },
    "id": "ls7DQOJ51WWJ"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "test_acc, test_precision, test_recall, test_f1, test_cm, test_labels, test_preds, result_df = evaluate_model(model, test_loader)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(f\"Precision: {test_precision:.3f}\")\n",
    "print(f\"Recall: {test_recall:.3f}\")\n",
    "print(f\"F1 Score: {test_f1:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T20:52:13.309042Z",
     "iopub.status.busy": "2024-12-05T20:52:13.308654Z",
     "iopub.status.idle": "2024-12-05T20:52:13.319955Z",
     "shell.execute_reply": "2024-12-05T20:52:13.318954Z",
     "shell.execute_reply.started": "2024-12-05T20:52:13.309010Z"
    },
    "id": "edPaznV51WWJ"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each label in true and predicted labels\n",
    "true_label_counts = Counter(test_labels)\n",
    "pred_label_counts = Counter(test_preds)\n",
    "\n",
    "print(\"\\nTrue Label Counts:\")\n",
    "print(true_label_counts)  # Outputs a dictionary, e.g., Counter({0: 150, 1: 150})\n",
    "\n",
    "print(\"\\nPredicted Label Counts:\")\n",
    "print(pred_label_counts)  # Outputs a dictionary, e.g., Counter({0: 160, 1: 140})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWOTj1104hWn"
   },
   "source": [
    "## Model Testing on New Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVrLK9J-5dKl"
   },
   "source": [
    "### Custom Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30ToEyLu1WWJ"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset for loading test images without labels\n",
    "class CustomTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for loading test images without labels.\n",
    "\n",
    "    Args:\n",
    "        test_dir (str): Path to the directory containing test images.\n",
    "        transform (callable, optional): Transformations to be applied to each image. Default is None.\n",
    "    \"\"\"\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the directory path and transformations.\n",
    "\n",
    "        Args:\n",
    "            test_dir (str): Path to the directory containing test images.\n",
    "            transform (callable, optional): Transformations to be applied to each image. Default is None.\n",
    "        \"\"\"\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        # Get all the files and filter only PNG files by checking file type\n",
    "        self.image_paths = [\n",
    "            os.path.join(test_dir, filename)\n",
    "            for filename in os.listdir(test_dir)\n",
    "            if imghdr.what(os.path.join(test_dir, filename)) == 'png'\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of images in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of images in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves an image and its file path at the specified index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the image to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - image (PIL.Image or torch.Tensor): The processed image.\n",
    "                - image_path (str): The file path of the image.\n",
    "        \"\"\"\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_path\n",
    "\n",
    "\n",
    "# Define transformations (adjust this as per your model's requirements)\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okLeQM8p5lnj"
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtQBOieJ1WWJ"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = timm.create_model('dpn68b.mx_in1k', pretrained=True, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(\"dpn68b.mx_in1k.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTwAeVAE5p13"
   },
   "source": [
    "### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yb14gr61WWJ"
   },
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_dir = '/path/to/new_test_dataset'  # define the path for the new dataset on which you need the model to provide predictions\n",
    "test_dataset = CustomTestDataset(test_dir=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kviRKpyv5vLx"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgTOuYCm5a6d"
   },
   "outputs": [],
   "source": [
    "# Function to run inference and save results to CSV\n",
    "def run_inference(model, data_loader, device=\"cuda\"):\n",
    "    all_preds = []\n",
    "    all_paths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, paths in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)  # Get the class predictions\n",
    "\n",
    "            # Collect predictions and image paths\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_paths.extend(paths)\n",
    "\n",
    "    # Save results to CSV\n",
    "    test_results_df = pd.DataFrame({\n",
    "        \"Image Path\": all_paths,\n",
    "        \"Prediction\": all_preds\n",
    "    })\n",
    "\n",
    "    # Save to CSV file\n",
    "    test_results_df.to_csv('test_predictions_dpn.csv', index=False)\n",
    "    print(f\"Predictions saved to 'test_predictions.csv'.\")\n",
    "\n",
    "# Run inference and save predictions\n",
    "run_inference(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4qBjDKNd_hV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6227568,
     "sourceId": 10097715,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6228649,
     "sourceId": 10099121,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6230540,
     "sourceId": 10101572,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6234398,
     "sourceId": 10106662,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6238291,
     "sourceId": 10111734,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
