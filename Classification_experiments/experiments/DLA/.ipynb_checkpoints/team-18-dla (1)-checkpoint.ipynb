{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10111006,"sourceType":"datasetVersion","datasetId":6237750},{"sourceId":188135,"sourceType":"modelInstanceVersion","modelInstanceId":160392,"modelId":182767},{"sourceId":188206,"sourceType":"modelInstanceVersion","modelInstanceId":160461,"modelId":182833},{"sourceId":189370,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":161461,"modelId":183829},{"sourceId":189533,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":161597,"modelId":183965}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, datasets\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights, resnet18\nfrom PIL import Image\nfrom tqdm import tqdm\nimport re\nimport json\nimport torch.nn.functional as F\nimport shutil\nimport pathlib\nfrom pathlib import Path","metadata":{"id":"kMWxycares-g","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:20.507901Z","iopub.execute_input":"2024-12-06T12:06:20.508743Z","iopub.status.idle":"2024-12-06T12:06:27.488940Z","shell.execute_reply.started":"2024-12-06T12:06:20.508705Z","shell.execute_reply":"2024-12-06T12:06:27.487829Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"weights = \"./DLA_corrected_weights.pth\" \ntestpath = \"./testdataset\"\ndevice = \"cuda\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:27.490608Z","iopub.execute_input":"2024-12-06T12:06:27.491082Z","iopub.status.idle":"2024-12-06T12:06:27.495560Z","shell.execute_reply.started":"2024-12-06T12:06:27.491052Z","shell.execute_reply":"2024-12-06T12:06:27.494584Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def get_sorted_image_paths(folder_path):\n   \n    try:\n        files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n\n        def extract_number(filename):\n            match = re.search(r'\\d+', filename)\n            return int(match.group()) if match else float('inf')\n\n        sorted_files = sorted(files, key=extract_number)\n\n        sorted_paths = [os.path.join(folder_path, file) for file in sorted_files]\n\n        return np.array(sorted_paths)\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return np.array([])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:27.496753Z","iopub.execute_input":"2024-12-06T12:06:27.497043Z","iopub.status.idle":"2024-12-06T12:06:27.508495Z","shell.execute_reply.started":"2024-12-06T12:06:27.497019Z","shell.execute_reply":"2024-12-06T12:06:27.507570Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"sorted_image_paths = get_sorted_image_paths(testpath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:27.510837Z","iopub.execute_input":"2024-12-06T12:06:27.511179Z","iopub.status.idle":"2024-12-06T12:06:28.706295Z","shell.execute_reply.started":"2024-12-06T12:06:27.511151Z","shell.execute_reply":"2024-12-06T12:06:28.705518Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"transform_test = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])","metadata":{"id":"AhUdZmOfi5m3","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:28.707290Z","iopub.execute_input":"2024-12-06T12:06:28.707557Z","iopub.status.idle":"2024-12-06T12:06:28.716668Z","shell.execute_reply.started":"2024-12-06T12:06:28.707524Z","shell.execute_reply":"2024-12-06T12:06:28.715934Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, image_paths, transform=None):\n        \n        self.image_paths = image_paths  \n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = np.array(image)\n        if self.transform:\n            augmented = self.transform(image=image) \n            image = augmented[\"image\"]\n\n        img_name = os.path.basename(img_path)\n        return image, img_name","metadata":{"id":"T-34vGsljlsK","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:28.717734Z","iopub.execute_input":"2024-12-06T12:06:28.718109Z","iopub.status.idle":"2024-12-06T12:06:28.727073Z","shell.execute_reply.started":"2024-12-06T12:06:28.718066Z","shell.execute_reply":"2024-12-06T12:06:28.726102Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset = ImageDataset(image_paths = sorted_image_paths, transform=transform_test)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)","metadata":{"id":"sUL0SRv3kk0-","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:28.728068Z","iopub.execute_input":"2024-12-06T12:06:28.728312Z","iopub.status.idle":"2024-12-06T12:06:28.741043Z","shell.execute_reply.started":"2024-12-06T12:06:28.728287Z","shell.execute_reply":"2024-12-06T12:06:28.740175Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\"\"\"\nThis module implements a Deep Layer Aggregation (DLA) model with components like `BasicBlock`, `Root`, `Tree`, and `DLA`.\n\nClasses:\n--------\nBasicBlock:\n    A basic residual block with optional shortcut connections.\n\n    Methods:\n        __init__(in_planes, planes, stride=1): Initializes the block.\n        forward(x): Performs the forward pass.\n\nRoot:\n    Combines feature maps via concatenation, applies convolution, batch normalization, and ReLU activation.\n\n    Methods:\n        __init__(in_channels, out_channels, kernel_size=1): Initializes the Root module.\n        forward(xs): Combines and processes feature maps.\n\nTree:\n    A recursive structure for hierarchical feature aggregation.\n\n    Methods:\n        __init__(block, in_channels, out_channels, level=1, stride=1): Initializes the Tree.\n        forward(x): Aggregates and processes features.\n\nDLA:\n    The main Deep Layer Aggregation model for classification tasks.\n\n    Methods:\n        __init__(block=BasicBlock, num_classes=2): Initializes the DLA model.\n        forward(x): Passes input through DLA layers for classification.\n\nUsage:\n------\n- `BasicBlock`: Core block for residual operations.\n- `Root`: Combines hierarchical features.\n- `Tree`: Builds hierarchical aggregation.\n- `DLA`: Full model for feature extraction and classification.\n\"\"\"\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass Root(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=1):\n        super(Root, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels, out_channels, kernel_size,\n            stride=1, padding=(kernel_size - 1) // 2, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, xs):\n        x = torch.cat(xs, 1)\n        out = F.relu(self.bn(self.conv(x)))\n        return out\n\nclass Tree(nn.Module):\n    def __init__(self, block, in_channels, out_channels, level=1, stride=1):\n        super(Tree, self).__init__()\n        self.level = level\n        if level == 1:\n            self.root = Root(2*out_channels, out_channels)\n            self.left_node = block(in_channels, out_channels, stride=stride)\n            self.right_node = block(out_channels, out_channels, stride=1)\n        else:\n            self.root = Root((level+2)*out_channels, out_channels)\n            for i in reversed(range(1, level)):\n                subtree = Tree(block, in_channels, out_channels,\n                               level=i, stride=stride)\n                self.__setattr__('level_%d' % i, subtree)\n            self.prev_root = block(in_channels, out_channels, stride=stride)\n            self.left_node = block(out_channels, out_channels, stride=1)\n            self.right_node = block(out_channels, out_channels, stride=1)\n\n    def forward(self, x):\n        xs = [self.prev_root(x)] if self.level > 1 else []\n        for i in reversed(range(1, self.level)):\n            level_i = self.__getattr__('level_%d' % i)\n            x = level_i(x)\n            xs.append(x)\n        x = self.left_node(x)\n        xs.append(x)\n        x = self.right_node(x)\n        xs.append(x)\n        out = self.root(xs)\n        return out\n\nclass DLA(nn.Module):\n    def __init__(self, block=BasicBlock, num_classes=2):\n        super(DLA, self).__init__()\n        self.base = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(16),\n            nn.ReLU(True)\n        )\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(16),\n            nn.ReLU(True)\n        )\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True)\n        )\n\n        self.layer3 = Tree(block,  32,  64, level=1, stride=1)\n        self.layer4 = Tree(block,  64, 128, level=2, stride=2)\n        self.layer5 = Tree(block, 128, 256, level=2, stride=2)\n        self.layer6 = Tree(block, 256, 512, level=1, stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        out = self.base(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:28.742154Z","iopub.execute_input":"2024-12-06T12:06:28.742433Z","iopub.status.idle":"2024-12-06T12:06:28.762269Z","shell.execute_reply.started":"2024-12-06T12:06:28.742407Z","shell.execute_reply":"2024-12-06T12:06:28.761532Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = DLA()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:28.763263Z","iopub.execute_input":"2024-12-06T12:06:28.763536Z","iopub.status.idle":"2024-12-06T12:06:28.994283Z","shell.execute_reply.started":"2024-12-06T12:06:28.763504Z","shell.execute_reply":"2024-12-06T12:06:28.993534Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":" # PUT WEIGHTS HERE\ncheckpoint = torch.load(weights)","metadata":{"id":"XHkG4GD5lEBU","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:28.997802Z","iopub.execute_input":"2024-12-06T12:06:28.998070Z","iopub.status.idle":"2024-12-06T12:06:30.055430Z","shell.execute_reply.started":"2024-12-06T12:06:28.998046Z","shell.execute_reply":"2024-12-06T12:06:30.054660Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/3609530691.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(weights)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"if \"net\" in checkpoint:\n        state_dict = checkpoint[\"net\"]\n        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n        print(\"net\")\nelif \"state_dict\" in checkpoint:\n        state_dict = checkpoint[\"state_dict\"]\n        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\nelse:\n        state_dict = checkpoint","metadata":{"id":"XHkG4GD5lEBU","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:30.056747Z","iopub.execute_input":"2024-12-06T12:06:30.057165Z","iopub.status.idle":"2024-12-06T12:06:30.064309Z","shell.execute_reply.started":"2024-12-06T12:06:30.057121Z","shell.execute_reply":"2024-12-06T12:06:30.063289Z"}},"outputs":[{"name":"stdout","text":"net\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.load_state_dict(state_dict, strict=False)\nmodel.to(device)","metadata":{"id":"XHkG4GD5lEBU","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:30.065479Z","iopub.execute_input":"2024-12-06T12:06:30.065758Z","iopub.status.idle":"2024-12-06T12:06:30.140545Z","shell.execute_reply.started":"2024-12-06T12:06:30.065731Z","shell.execute_reply":"2024-12-06T12:06:30.139570Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DLA(\n  (base): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (layer1): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (layer2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (layer3): Tree(\n    (root): Root(\n      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (left_node): BasicBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (right_node): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Tree(\n    (root): Root(\n      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (level_1): Tree(\n      (root): Root(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (left_node): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (right_node): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n    )\n    (prev_root): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (left_node): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (right_node): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer5): Tree(\n    (root): Root(\n      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (level_1): Tree(\n      (root): Root(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (left_node): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (right_node): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n    )\n    (prev_root): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (left_node): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (right_node): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer6): Tree(\n    (root): Root(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (left_node): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (right_node): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=512, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"root_dir = Path(os.getcwd())\nFake_dir = os.path.join(root_dir, \"Fake_Folder\")\nos.makedirs(Fake_dir, exist_ok=True)","metadata":{"id":"V0RW_nwsk8MU","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:06:30.141643Z","iopub.execute_input":"2024-12-06T12:06:30.141957Z","iopub.status.idle":"2024-12-06T12:06:30.146757Z","shell.execute_reply.started":"2024-12-06T12:06:30.141928Z","shell.execute_reply":"2024-12-06T12:06:30.145715Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"results1 = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:14:48.702189Z","iopub.execute_input":"2024-12-06T12:14:48.703078Z","iopub.status.idle":"2024-12-06T12:14:48.706944Z","shell.execute_reply.started":"2024-12-06T12:14:48.703041Z","shell.execute_reply":"2024-12-06T12:14:48.705942Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"index = 1\nwith torch.no_grad():\n    for images, img_paths in dataloader:\n        images = images.to(device)\n        outputs = model(images)  \n        _, preds = torch.max(outputs, 1) \n        \n        for img_path, pred in zip(img_paths, preds):\n            prediction_label = \"fake\" if pred.item() == 0 else \"real\"\n            \n            results1.append({\n                \"index\":img_path[:-4] ,\n                \"prediction\": prediction_label\n            })\n            index += 1\n            if pred.item() == 0:\n                shutil.copy(os.path.join(testpath, img_path), Fake_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:14:52.215873Z","iopub.execute_input":"2024-12-06T12:14:52.216240Z","iopub.status.idle":"2024-12-06T12:14:53.066015Z","shell.execute_reply.started":"2024-12-06T12:14:52.216209Z","shell.execute_reply":"2024-12-06T12:14:53.064950Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"json_filename = \"./DLA.json\"  \nwith open(json_filename, \"w\") as json_file:\n    json.dump(results1, json_file, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:15:01.655460Z","iopub.execute_input":"2024-12-06T12:15:01.655815Z","iopub.status.idle":"2024-12-06T12:15:01.663179Z","shell.execute_reply.started":"2024-12-06T12:15:01.655787Z","shell.execute_reply":"2024-12-06T12:15:01.662302Z"}},"outputs":[],"execution_count":31}]}