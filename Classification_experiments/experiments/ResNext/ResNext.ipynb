{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing necessary modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Instantiation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining the ResNext architecture \n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    A building block of the ResNeXt architecture using group convolutions and a bottleneck structure.\n",
    "\n",
    "    Args:\n",
    "        in_planes (int): Number of input channels.\n",
    "        cardinality (int): Number of groups in the group convolution (Default: 32).\n",
    "        bottleneck_width (int): Width of the bottleneck (Default: 4).\n",
    "        stride (int): Stride for the second convolution (Default: 1).\n",
    "\n",
    "    Layers:\n",
    "        - Conv1: 1x1 convolution.\n",
    "        - Conv2: 3x3 group convolution.\n",
    "        - Conv3: 1x1 convolution.\n",
    "        - Shortcut: Skip connection to match dimensions if needed.\n",
    "\n",
    "    Forward pass:\n",
    "        Applies convolutions, batch normalization, ReLU activations, and a shortcut connection.\n",
    "    \"\"\"\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, in_planes, cardinality=32, bottleneck_width=4, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        group_width = cardinality * bottleneck_width\n",
    "        self.conv1 = nn.Conv2d(in_planes, group_width, kernel_size=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(group_width)\n",
    "        self.conv2 = nn.Conv2d(group_width, group_width, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=True)\n",
    "        self.conv3 = nn.Conv2d(group_width, self.expansion*group_width, kernel_size=1, bias=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*group_width:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*group_width, kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.conv3(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNeXt(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNeXt model with a configurable number of blocks, cardinality, and bottleneck width.\n",
    "\n",
    "    Args:\n",
    "        num_blocks (list): List of integers specifying the number of blocks in each layer.\n",
    "        cardinality (int): Number of groups in the group convolutions (Default: 32).\n",
    "        bottleneck_width (int): Width of the bottleneck (Default: 4).\n",
    "        num_classes (int): Number of output classes (Default: 2, for binary classification).\n",
    "\n",
    "    Layers:\n",
    "        - Conv1: Initial 3x3 convolution.\n",
    "        - Layer1, Layer2, Layer3: Stacked blocks of `Block` class, each with increasing stride.\n",
    "        - Linear1: Fully connected layer with 512 units.\n",
    "        - Linear2: Output layer with `num_classes` units.\n",
    "\n",
    "    Forward pass:\n",
    "        Performs convolutions, batch normalization, ReLU activations, and fully connected layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks, cardinality, bottleneck_width, num_classes=2):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.cardinality = cardinality\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, bias=True, padding=1)\n",
    "        self.layer1 = self._make_layer(num_blocks[0], 1)\n",
    "        self.layer2 = self._make_layer(num_blocks[1], 2)\n",
    "        self.layer3 = self._make_layer(num_blocks[2], 2)\n",
    "        self.linear1 = nn.Linear(cardinality*bottleneck_width*512, 512)\n",
    "        self.linear2 = nn.Linear(512, num_classes)  # Binary classification output (real/fake)\n",
    "\n",
    "    def _make_layer(self, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(Block(self.in_planes, self.cardinality, self.bottleneck_width, stride))\n",
    "            self.in_planes = Block.expansion * self.cardinality * self.bottleneck_width\n",
    "        self.bottleneck_width *= 2\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = F.relu(self.linear1(out))\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "def ResNeXt29_2x64d():\n",
    "    return ResNeXt(num_blocks=[3,3,3], cardinality=2, bottleneck_width=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unzipping custom_dataset.zip\n",
    "#The unzipping results in 2 datasets - custom_dataset and test_dataset - being created in the working directory\n",
    "with zipfile.ZipFile(\"custom_dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('custom_dataset')\n",
    "\n",
    "# Unzipping tes-final.zip\n",
    "with zipfile.ZipFile(\"test_dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to remove .ipynb_checkpoints folder from the dataset\n",
    "def remove_ipynb_checkpoints(dataset_dir):\n",
    "    for root, dirs, files in os.walk(dataset_dir, topdown=False):\n",
    "        # Check if .ipynb_checkpoints is in the directories list\n",
    "        if '.ipynb_checkpoints' in dirs:\n",
    "            # Construct the full path to the .ipynb_checkpoints directory\n",
    "            checkpoint_dir = os.path.join(root, '.ipynb_checkpoints')\n",
    "            # Remove the .ipynb_checkpoints directory and all its contents\n",
    "            shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "# Paths to the train and test directories\n",
    "train_dir = 'custom_dataset/train'\n",
    "test_dir = 'custom_dataset/test'\n",
    "\n",
    "# Remove .ipynb_checkpoints from both train and test directories\n",
    "remove_ipynb_checkpoints(train_dir)\n",
    "remove_ipynb_checkpoints(test_dir)\n",
    "remove_ipynb_checkpoints('test_dataset/test-interiit/perturbed_images_32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading the dataset and performing necessary transforms to then train the model \n",
    "train_dir = 'custom_dataset/train'\n",
    "test_dir = 'custom_dataset/test'  # Path to your test data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "#Setup for binary classification\n",
    "model = ResNeXt29_2x64d().to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "#Test Accuracy after training\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "#Save model weights\n",
    "torch.save(model.state_dict(), 'resnext_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model and load the trained weights to print out the classification metrics \n",
    "model = ResNeXt29_2x64d().to(device)\n",
    "model.load_state_dict(torch.load('resnext_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Load the test dataset\n",
    "test_dir = 'custom_dataset/test'\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(test_dir), transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Evaluate model on the test set and compute the confusion matrix\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manually load the new test dataset (perturbed images)\n",
    "perturbed_test_dir = 'test_dataset/test-interiit/perturbed_images_32'\n",
    "perturbed_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "#Sort the filenames in ascending order (numeric sort)\n",
    "sorted_filenames = sorted(os.listdir(perturbed_test_dir), key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "#Prepare for storing predictions\n",
    "predictions = []\n",
    "filenames = []\n",
    "\n",
    "#Process each image\n",
    "for filename in sorted_filenames:\n",
    "    image_path = os.path.join(perturbed_test_dir, filename)\n",
    "    \n",
    "    #Open image, apply transformations, and send to device\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = perturbed_transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class (0 or 1)\n",
    "        filenames.append(filename)\n",
    "        predictions.append(predicted.item())  # Add 0 or 1\n",
    "\n",
    "# Create a DataFrame with filenames and their corresponding predictions\n",
    "df = pd.DataFrame({\n",
    "    \"filename\": filenames,\n",
    "    \"prediction\": predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('final_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6218149,
     "sourceId": 10085465,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
