{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Prediciton notebook for test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficentnetv2s data loading and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install scikit-learn\n",
    "!pip install scikit-image\n",
    "!pip install opencv-python\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.transforms import transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:24:58.383142Z",
     "iopub.status.busy": "2024-12-06T08:24:58.382764Z",
     "iopub.status.idle": "2024-12-06T08:25:34.650975Z",
     "shell.execute_reply": "2024-12-06T08:25:34.650002Z",
     "shell.execute_reply.started": "2024-12-06T08:24:58.383098Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    A custom PyTorch dataset for loading and preprocessing images, paired with their corresponding labels.\n",
    "    The images are read from a list of file paths, optionally transformed, and returned alongside their labels.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list of str): A list of file paths pointing to the images.\n",
    "        labels (list of int or float): A list of labels corresponding to each image in `file_paths`.\n",
    "        transform (callable, optional): A function/transform to apply to the images. Defaults to None.\n",
    "\n",
    "    Attributes:\n",
    "        file_paths (list): List of image file paths.\n",
    "        labels (list): List of labels corresponding to the images.\n",
    "        transform (callable): Transformation function applied to each image.\n",
    "\n",
    "    Methods:\n",
    "        __len__():\n",
    "            Returns the number of image-label pairs in the dataset.\n",
    "        __getitem__(index):\n",
    "            Loads an image at the given index, applies transformations (if any), \n",
    "            and returns the image along with its label.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        img = read_image(img_path).float() / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Dataset Preparation Function\n",
    "def prepare_dataset(base_dir):\n",
    "    if not os.path.isdir(base_dir):\n",
    "        raise ValueError(f\"Directory {base_dir} does not exist.\")\n",
    "\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    label_map = {\"FAKE\": 0, \"REAL\": 1}  # 0: Fake, 1: Real\n",
    "\n",
    "    for subfolder in label_map:\n",
    "        folder_path = os.path.join(base_dir, subfolder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"Warning: Subfolder {subfolder} not found in {base_dir}. Skipping...\")\n",
    "            continue\n",
    "        for fname in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, fname)\n",
    "            if os.path.isfile(file_path) and fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "                file_paths.append(file_path)\n",
    "                labels.append(label_map[subfolder])\n",
    "\n",
    "    return file_paths, labels\n",
    "\n",
    "\n",
    "test_dir = \"/test\"\n",
    "\n",
    "# Preparing Dataset\n",
    "\n",
    "test_paths, test_labels = prepare_dataset(test_dir)\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(test_paths, test_labels, transform=test_transform)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model Definition\n",
    "class CustomEffNetV2S(nn.Module):\n",
    "    '''\n",
    "    A custom implementation of the EfficientNet V2-S model for binary or multi-class classification tasks.\n",
    "\n",
    "    This class modifies the default EfficientNet V2-S architecture by replacing the final classifier layer \n",
    "    to adapt to a specific number of output classes. Additionally, a dropout layer is added after the \n",
    "    classifier to help prevent overfitting.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int, optional): The number of output classes. Defaults to 1 (binary classification).\n",
    "        dropout_rate (float, optional): The probability of an element being zeroed in the dropout layer. \n",
    "                                        Defaults to 0.5.\n",
    "\n",
    "    Attributes:\n",
    "        effnet (EfficientNetV2_S): The EfficientNet V2-S base model, preloaded with weights.\n",
    "        dropout (nn.Dropout): A dropout layer applied to the output of the classifier.\n",
    "\n",
    "    Methods:\n",
    "        forward(x):\n",
    "            Forward pass of the model. Takes input tensor `x`, processes it through EfficientNet V2-S \n",
    "            and applies dropout before returning the output.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, num_classes=1, dropout_rate=0.5):\n",
    "        super(CustomEffNetV2S, self).__init__()\n",
    "        self.effnet = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "        self.effnet.classifier[1] = nn.Linear(self.effnet.classifier[1].in_features, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.effnet(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_efficient_net = CustomEffNetV2S().to(DEVICE)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_efficient_net.parameters(), lr=3e-4)\n",
    "\n",
    "# Training Loop\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:25:34.652952Z",
     "iopub.status.busy": "2024-12-06T08:25:34.652675Z",
     "iopub.status.idle": "2024-12-06T08:25:35.155207Z",
     "shell.execute_reply": "2024-12-06T08:25:35.154032Z",
     "shell.execute_reply.started": "2024-12-06T08:25:34.652925Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_efficient_net = CustomEffNetV2S().to(DEVICE)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_efficient_net.parameters(), lr=3e-4)\n",
    "device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:25:35.157046Z",
     "iopub.status.busy": "2024-12-06T08:25:35.156614Z",
     "iopub.status.idle": "2024-12-06T08:25:35.363251Z",
     "shell.execute_reply": "2024-12-06T08:25:35.362334Z",
     "shell.execute_reply.started": "2024-12-06T08:25:35.157001Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/126845967.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_weights = torch.load(best_weights_path, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights_path = \"ensemble_weights/effnet\"\n",
    "best_weights = torch.load(best_weights_path, map_location=DEVICE)\n",
    "# Load the best weights into the model\n",
    "model_efficient_net.load_state_dict(best_weights, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vit -tiny data loading and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:27:09.579872Z",
     "iopub.status.busy": "2024-12-06T08:27:09.579123Z",
     "iopub.status.idle": "2024-12-06T08:27:13.813671Z",
     "shell.execute_reply": "2024-12-06T08:27:13.812782Z",
     "shell.execute_reply.started": "2024-12-06T08:27:09.579830Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "num_classes = 2  # Assuming CIFAKE has two classes: Real and Fake\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform2 = T.Compose([\n",
    "    T.Resize(size=(32, 32)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "test_dataset1 = datasets.ImageFolder(root=\"/test\", transform=transform2)\n",
    "test_loader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:27:13.815579Z",
     "iopub.status.busy": "2024-12-06T08:27:13.815217Z",
     "iopub.status.idle": "2024-12-06T08:27:13.832257Z",
     "shell.execute_reply": "2024-12-06T08:27:13.831298Z",
     "shell.execute_reply.started": "2024-12-06T08:27:13.815543Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class CombinedViTModel(nn.Module):\n",
    "    '''\n",
    "    A combined Vision Transformer (ViT) model for binary classification. This model utilizes a pre-trained ViT base\n",
    "    model (e.g., ViT Tiny) for feature extraction and adds a custom classification head on top.\n",
    "\n",
    "    The base model's classification head is removed to focus only on the embedding features (CLS token). A new \n",
    "    linear classifier is added to perform binary classification on the extracted features.\n",
    "\n",
    "    Args:\n",
    "        base_model_name (str, optional): The name of the pre-trained ViT model to use. Defaults to 'vit_tiny_patch16_224'.\n",
    "        embedding_dim (int, optional): The dimension of the embeddings output by the ViT model. Defaults to 192.\n",
    "        num_classes (int, optional): The number of output classes. Defaults to 2 (binary classification).\n",
    "\n",
    "    Attributes:\n",
    "        base_model (nn.Module): The pre-trained Vision Transformer model (with the classification head removed).\n",
    "        classifier (nn.Linear): A linear layer used as the classification head, which takes the embeddings from \n",
    "                                the base model and outputs logits for binary classification.\n",
    "\n",
    "    Methods:\n",
    "        forward(x):\n",
    "            Forward pass of the model. Extracts embeddings from the ViT model and passes them through the \n",
    "            classifier to obtain logits.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, base_model_name='vit_tiny_patch16_224', embedding_dim=192, num_classes=2):\n",
    "        super(CombinedViTModel, self).__init__()\n",
    "        # Load pre-trained ViT model\n",
    "        self.base_model = timm.create_model(base_model_name, pretrained=True, img_size = 32)\n",
    "        self.base_model.head = nn.Identity()  # Nullify the classification head\n",
    "        \n",
    "        # New classification head\n",
    "        self.classifier = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract embeddings (CLS token) from the base model\n",
    "        embeddings = self.base_model.forward_features(x)[:, 0]  # CLS token is the first token\n",
    "        logits = self.classifier(embeddings)  # Binary classification logits\n",
    "        return embeddings, logits\n",
    "\n",
    "\n",
    "count1 = 0\n",
    "# Define the Combined Loss Function\n",
    "class CombinedLoss(nn.Module):\n",
    "    '''\n",
    "    A custom loss function that combines Binary Cross-Entropy (BCE) loss and a contrastive loss \n",
    "    for tasks that involve both classification and representation learning.\n",
    "\n",
    "    The BCE loss is used for binary classification tasks, while the contrastive loss encourages \n",
    "    similar embeddings for samples with the same label and dissimilar embeddings for samples with \n",
    "    different labels. The two losses are weighted and combined into a single loss value.\n",
    "\n",
    "    Args:\n",
    "        margin (float, optional): The margin used in the contrastive loss. Defaults to 1.0.\n",
    "        temperature (float, optional): The temperature scaling factor for the contrastive loss. Defaults to 0.07.\n",
    "        lambda_contrastive (float, optional): The weight for the contrastive loss term when combining with BCE loss. Defaults to 0.5.\n",
    "\n",
    "    Attributes:\n",
    "        bce_loss (nn.BCEWithLogitsLoss): The Binary Cross-Entropy loss function.\n",
    "        margin (float): The margin for the contrastive loss.\n",
    "        temperature (float): The temperature scaling factor for the contrastive loss.\n",
    "        lambda_contrastive (float): The weight for combining contrastive loss with BCE loss.\n",
    "\n",
    "    Methods:\n",
    "        forward(embeddings, logits, labels):\n",
    "            Computes the combined loss by adding weighted BCE loss and contrastive loss.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, margin=1.0, temperature=0.07, lambda_contrastive=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.margin = margin\n",
    "        self.temperature = temperature\n",
    "        self.lambda_contrastive = lambda_contrastive\n",
    "\n",
    "    def forward(self, embeddings, logits, labels):\n",
    "        global count1\n",
    "        # Compute BCE Loss\n",
    "        bce_loss = self.bce_loss(logits, labels.float().unsqueeze(1))\n",
    "        \n",
    "        # Compute Contrastive Loss\n",
    "        contrastive_loss = self.contrastive_loss(embeddings, labels)\n",
    "        \n",
    "        # Combine the Losses\n",
    "        combined_loss = bce_loss + self.lambda_contrastive * contrastive_loss\n",
    "        if count1 == 0:\n",
    "            print(bce_loss)\n",
    "            print(contrastive_loss)\n",
    "            count1 += 1\n",
    "        return combined_loss\n",
    "\n",
    "    def contrastive_loss(self, features, labels):\n",
    "        # Normalize features\n",
    "        features = F.normalize(features, dim=1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        sim_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        \n",
    "        # Create label masks\n",
    "        labels = labels.view(-1, 1)\n",
    "        mask_pos = torch.eq(labels, labels.T).float()\n",
    "        mask_neg = 1 - mask_pos\n",
    "        \n",
    "        # Remove diagonal\n",
    "        mask_pos = mask_pos - torch.eye(mask_pos.shape[0], device=mask_pos.device)\n",
    "        \n",
    "        # Compute positive and negative losses\n",
    "        exp_sim = torch.exp(sim_matrix)\n",
    "        log_prob = sim_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        # Mean over positive pairs\n",
    "        mean_log_prob_pos = (mask_pos * log_prob).sum(1) / mask_pos.sum(1).clamp(min=1e-8)\n",
    "        \n",
    "        return -mean_log_prob_pos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:27:13.835249Z",
     "iopub.status.busy": "2024-12-06T08:27:13.834404Z",
     "iopub.status.idle": "2024-12-06T08:27:14.187592Z",
     "shell.execute_reply": "2024-12-06T08:27:14.186714Z",
     "shell.execute_reply.started": "2024-12-06T08:27:13.835222Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2704127635.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_weights = torch.load(best_weights_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temperature = 0.5\n",
    "lambda_contrastive = 0.01\n",
    "\n",
    "model_tinyvit = CombinedViTModel().to(device)\n",
    "criterion = CombinedLoss(temperature=temperature, lambda_contrastive=lambda_contrastive).to(device)\n",
    "optimizer = optim.Adam(model_tinyvit.parameters(), lr=learning_rate)\n",
    "\n",
    "best_weights_path = \"/ensemble_weights/ViT_tiny_corrected_dataset_weights.pth\"\n",
    "best_weights = torch.load(best_weights_path, map_location=device)\n",
    "model_tinyvit.load_state_dict(best_weights, strict=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet-18 data loading and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:27:47.395333Z",
     "iopub.status.busy": "2024-12-06T08:27:47.394397Z",
     "iopub.status.idle": "2024-12-06T08:27:47.691034Z",
     "shell.execute_reply": "2024-12-06T08:27:47.690145Z",
     "shell.execute_reply.started": "2024-12-06T08:27:47.395300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2691916229.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/kaggle/input/weightss/corrected_Weights 2/best_model_resnet_4th.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(device)\n",
    "model_resnet.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "num_classes = 2\n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features,num_classes)\n",
    "model_resnet.to(device)\n",
    "checkpoint = torch.load('ensemble_weights/best_model_resnet_4th.pth')\n",
    "model_resnet.load_state_dict(checkpoint)\n",
    "model_resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official Adobe dataset label predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:54:30.000268Z",
     "iopub.status.busy": "2024-12-06T08:54:29.999909Z",
     "iopub.status.idle": "2024-12-06T08:54:30.009860Z",
     "shell.execute_reply": "2024-12-06T08:54:30.009000Z",
     "shell.execute_reply.started": "2024-12-06T08:54:30.000237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the test images\n",
    "test_data_path = \"/adobe_data\"\n",
    "\n",
    "transforms2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "# Define a custom dataset for the test data\n",
    "class CustomTestDataset(Dataset):\n",
    "    '''\n",
    "    A custom PyTorch dataset for loading and preprocessing images for testing. \n",
    "    This dataset reads images from a specified directory, applies transformations \n",
    "    (if any), and returns the image along with its file path.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory containing the test images.\n",
    "        transform (callable, optional): A function/transform to be applied to the images. \n",
    "                                        Defaults to None.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (str): Path to the directory containing test images.\n",
    "        image_paths (list): A list of file paths for images in the root directory.\n",
    "        transform (callable): The transformation function applied to the images.\n",
    "\n",
    "    Methods:\n",
    "        __len__():\n",
    "            Returns the number of images in the dataset.\n",
    "        __getitem__(index):\n",
    "            Loads an image at the given index, applies transformations (if any), \n",
    "            and returns the image along with its file path.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Ensure 3-channel images\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_path  # Returning image and its path for reference\n",
    "\n",
    "# Create the dataset\n",
    "test_dataset2 = CustomTestDataset(root_dir=test_data_path, transform=transforms2)\n",
    "\n",
    "# Create the dataloader\n",
    "test_loader2 = DataLoader(test_dataset2, batch_size=64, shuffle=False)  # Adjust batch_size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:54:39.085910Z",
     "iopub.status.busy": "2024-12-06T08:54:39.084957Z",
     "iopub.status.idle": "2024-12-06T08:54:39.861120Z",
     "shell.execute_reply": "2024-12-06T08:54:39.860294Z",
     "shell.execute_reply.started": "2024-12-06T08:54:39.085860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability saved to resnet_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_resnet.eval()\n",
    "# Lists to store predictions and file paths\n",
    "test_predictions = []\n",
    "image_paths = []\n",
    "# Hyperparameter for threshold\n",
    "threshold = 0.79  # Adjust as needed\n",
    "# Prediction loop\n",
    "print(\"Generating predictions on test data...\")\n",
    "with torch.no_grad():\n",
    "    for images, paths in tqdm(test_loader2):\n",
    "        images = images.to(device)\n",
    "        outputs = model_resnet(images)\n",
    "        prob = torch.softmax(outputs, dim=1)[:, 1] # Get probability of class 1 (real class)\n",
    "        test_predictions.extend(prob.cpu().numpy())\n",
    "        image_paths.extend(paths)\n",
    "\n",
    "# Save predictions to a file\n",
    "# Create a DataFrame for predictions and corresponding file paths\n",
    "predictions_df = pd.DataFrame({\"Image_Path\": image_paths, \"Prediction\": test_predictions})\n",
    "\n",
    "# Save to CSV\n",
    "predictions_df.to_csv(\"/resnet_predictions.csv\", index=False)\n",
    "print(\"Probability saved to resnet_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:54:45.251532Z",
     "iopub.status.busy": "2024-12-06T08:54:45.251180Z",
     "iopub.status.idle": "2024-12-06T08:54:45.260607Z",
     "shell.execute_reply": "2024-12-06T08:54:45.259855Z",
     "shell.execute_reply.started": "2024-12-06T08:54:45.251502Z"
    }
   },
   "outputs": [],
   "source": [
    "transform1 = T.Compose([\n",
    "    T.Resize(size=(32, 32)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "test_dataset1 = CustomTestDataset(root_dir=test_data_path, transform=transform1)\n",
    "\n",
    "# Create the dataloader\n",
    "test_loader1 = DataLoader(test_dataset1, batch_size=64, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:54:46.917317Z",
     "iopub.status.busy": "2024-12-06T08:54:46.916508Z",
     "iopub.status.idle": "2024-12-06T08:54:47.260976Z",
     "shell.execute_reply": "2024-12-06T08:54:47.260061Z",
     "shell.execute_reply.started": "2024-12-06T08:54:46.917284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on test data with TinyViT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing TinyViT: 100%|██████████| 5/5 [00:00<00:00, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/tinyvit_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_tinyvit.eval()\n",
    "\n",
    "test_predictions = []\n",
    "image_paths = []\n",
    "\n",
    "# Prediction loop\n",
    "print(\"Generating predictions on test data with TinyViT...\")\n",
    "with torch.no_grad():\n",
    "    for images, paths in tqdm(test_loader1, desc=\"Testing TinyViT\"):\n",
    "        images = images.to(device)\n",
    "        # Forward pass\n",
    "        _, logits = model_tinyvit(images)\n",
    "        # Get probabilities using sigmoid for binary classification\n",
    "        prob = torch.sigmoid(logits).squeeze()\n",
    "        # predicted = prob.round().long()\n",
    "        test_predictions.extend(prob.cpu().numpy())\n",
    "        image_paths.extend(paths)\n",
    "\n",
    "# Create a DataFrame for predictions and corresponding file paths\n",
    "predictions_df = pd.DataFrame({\"Image_Path\": image_paths, \"Prediction\": test_predictions})\n",
    "\n",
    "# Save to CSV (optional)\n",
    "output_file = \"/tinyvit_predictions.csv\"\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:54:50.381643Z",
     "iopub.status.busy": "2024-12-06T08:54:50.380801Z",
     "iopub.status.idle": "2024-12-06T08:54:50.393129Z",
     "shell.execute_reply": "2024-12-06T08:54:50.392271Z",
     "shell.execute_reply.started": "2024-12-06T08:54:50.381610Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    A custom PyTorch dataset for loading and preprocessing images from a list of file paths. \n",
    "    The images are read, optionally transformed, and returned for training or inference.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list of str): A list of file paths pointing to the images.\n",
    "        transform (callable, optional): A function/transform to apply to the images. \n",
    "                                        Defaults to None.\n",
    "\n",
    "    Attributes:\n",
    "        file_paths (list): List of image file paths.\n",
    "        transform (callable): Transformation function applied to each image.\n",
    "\n",
    "    Methods:\n",
    "        __len__():\n",
    "            Returns the number of images in the dataset.\n",
    "        __getitem__(index):\n",
    "            Loads an image at the given index, applies transformations (if any), \n",
    "            and returns the image.\n",
    "    '''\n",
    "    def __init__(self, file_paths,transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        img = read_image(img_path).float() / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "# Dataset Preparation Function\n",
    "def prepare_dataset(base_dir):\n",
    "    if not os.path.isdir(base_dir):\n",
    "        raise ValueError(f\"Directory {base_dir} does not exist.\")\n",
    "\n",
    "    file_paths = []\n",
    "    \n",
    "    for fname in os.listdir(base_dir):\n",
    "        file_path = os.path.join(base_dir, fname)\n",
    "        if os.path.isfile(file_path) and fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "            file_paths.append(file_path)\n",
    "    \n",
    "    return file_paths\n",
    "\n",
    "\n",
    "# Paths\n",
    "\n",
    "test_dir = \"/adobe_data\"\n",
    "\n",
    "# Prepare Dataset\n",
    "\n",
    "test_paths = prepare_dataset(test_dir)\n",
    "\n",
    "# Transforms\n",
    "# Transforms\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(test_paths, transform=test_transform)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:55:10.780397Z",
     "iopub.status.busy": "2024-12-06T08:55:10.779594Z",
     "iopub.status.idle": "2024-12-06T08:55:11.769246Z",
     "shell.execute_reply": "2024-12-06T08:55:11.768438Z",
     "shell.execute_reply.started": "2024-12-06T08:55:10.780365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on test data with EfficientNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing EfficientNet: 100%|██████████| 5/5 [00:00<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/efficientnet_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model_efficient_net.eval()\n",
    "\n",
    "# Lists to store predictions and file paths\n",
    "test_predictions = []\n",
    "test_image_paths = []\n",
    "\n",
    "# Hyperparameter for threshold\n",
    "threshold = 0.5  # Adjust as needed\n",
    "\n",
    "# Prediction loop\n",
    "print(\"Generating predictions on test data with EfficientNet...\")\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"Testing EfficientNet\"):\n",
    "        images = images.to(device)  # Move images to the device\n",
    "        outputs = model_efficient_net(images)\n",
    "        prob = torch.sigmoid(outputs).squeeze()\n",
    "        test_predictions.extend(prob.cpu().numpy())\n",
    "\n",
    "# Associate predictions with image paths\n",
    "test_image_paths = test_paths  # Paths are already available\n",
    "\n",
    "# Save predictions to a file\n",
    "# Create a DataFrame for predictions and corresponding file paths\n",
    "predictions_df = pd.DataFrame({\"Image_Path\": test_image_paths, \"Prediction\": test_predictions})\n",
    "\n",
    "# Save to CSV (optional)\n",
    "output_file = \"/efficientnet_predictions.csv\"\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:55:31.108552Z",
     "iopub.status.busy": "2024-12-06T08:55:31.108235Z",
     "iopub.status.idle": "2024-12-06T08:55:31.132780Z",
     "shell.execute_reply": "2024-12-06T08:55:31.131995Z",
     "shell.execute_reply.started": "2024-12-06T08:55:31.108527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predictions saved to /kaggle/working/final_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Load predictions from CSVs\n",
    "efficientnet_df = pd.read_csv(\"/efficientnet_predictions.csv\")\n",
    "tinyvit_df = pd.read_csv(\"/tinyvit_predictions.csv\")\n",
    "resnet_df = pd.read_csv(\"/resnet_predictions.csv\")\n",
    "\n",
    "# Merge DataFrames on Image_Path\n",
    "combined_df = efficientnet_df.merge(tinyvit_df, on=\"Image_Path\").merge(resnet_df, on=\"Image_Path\")\n",
    "\n",
    "# Assign weights to models (adjust as hyperparameters)\n",
    "weights = {\n",
    "    \"EfficientNet_Prob\": 0.6,\n",
    "    \"TinyViT_Prob\": 0.3,\n",
    "    \"ResNet_Prob\": 0.1\n",
    "}\n",
    "\n",
    "# Calculate weighted average\n",
    "combined_df[\"Weighted_Prob\"] = (\n",
    "    weights[\"EfficientNet_Prob\"] * combined_df[\"Prediction_x\"] +\n",
    "    weights[\"TinyViT_Prob\"] * combined_df[\"Prediction_y\"] +\n",
    "    weights[\"ResNet_Prob\"] * combined_df[\"Prediction\"]\n",
    ")\n",
    "\n",
    "# Apply a final threshold to classify as binary (fake or real)\n",
    "final_threshold = 0.52\n",
    "combined_df[\"Final_Prediction\"] = (combined_df[\"Weighted_Prob\"] >= final_threshold).astype(int)\n",
    "\n",
    "# Save final predictions to CSV\n",
    "output_file = \"/final_predictions.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"Final predictions saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To create json file of the Predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv('/final_predictions.csv')\n",
    "data['Final_Prediction']\n",
    "data['New_Image_Path'] = 0\n",
    "for i in range(len(data['Image_Path'])):\n",
    "  data['New_Image_Path'][i] = data['Image_Path'][i].split('/')[-1]\n",
    "data['New_Image_Path']\n",
    "data['Image_number'] =  0\n",
    "for i in range(len(data['Image_Path'])):\n",
    "  data['Image_number'][i]=data['New_Image_Path'][i].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_images = data\n",
    "data_for_images['Image_Path']\n",
    "data_for_images = data_for_images.drop(['Prediction_x','New_Image_Path','Prediction','Weighted_Prob','Prediction_y','Image_number'], axis=1)\n",
    "data_zero_prediction = data_for_images[data_for_images['Final_Prediction'] == 0]\n",
    "data_zero_prediction = data_zero_prediction[['Image_Path','Final_Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "out_folder = \"fake_images\"\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "for image_path in data_zero_prediction[\"Image_Path\"]:\n",
    "    try:\n",
    "        # Check if the file exists before attempting to copy\n",
    "        if os.path.exists(image_path):\n",
    "            shutil.copy(image_path, out_folder)\n",
    "        else:\n",
    "            print(f\"File not found: {image_path}\")\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Image_Path', 'New_Image_Path'], axis=1)\n",
    "data['Image_number'] = pd.to_numeric(data['Image_number'], errors='coerce')\n",
    "\n",
    "# Sort the DataFrame by the 'Image_number' column\n",
    "data = data.sort_values('Image_number')\n",
    "\n",
    "# Reset the index to have consecutive numbers\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Create a new 'Image_number' column with consecutive integers starting from 1\n",
    "data['Image_number'] = range(1, len(data) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data\n",
    "data2 = data.drop(['Prediction_x', 'Prediction_y', 'Weighted_Prob','Prediction'], axis=1)\n",
    "data2['Final_Prediction'] = data2['Final_Prediction'].replace({0: 'fake', 1: 'real'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the column types are native Python types\n",
    "data2['Image_number'] = data2['Image_number'].astype(int)\n",
    "data2['Final_Prediction'] = data2['Final_Prediction'].astype(str)\n",
    "\n",
    "# Convert dataframe to desired JSON format\n",
    "result = data2.apply(lambda row: {\"index\": row['Image_number'], \"prediction\": row['Final_Prediction']}, axis=1).tolist()\n",
    "\n",
    "# Save the JSON output\n",
    "json_output = json.dumps(result, indent=4)\n",
    "\n",
    "# Save the file to Colab\n",
    "output_file_path = \"/predictions.json\"\n",
    "with open(output_file_path, \"w\") as json_file:\n",
    "    json_file.write(json_output)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6219482,
     "sourceId": 10087165,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6227744,
     "sourceId": 10097957,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6227997,
     "sourceId": 10098295,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6228120,
     "sourceId": 10098447,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6228762,
     "sourceId": 10099262,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6228786,
     "sourceId": 10099294,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6229425,
     "sourceId": 10100104,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6235232,
     "sourceId": 10107727,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6235272,
     "sourceId": 10107773,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6235769,
     "sourceId": 10108391,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6236120,
     "sourceId": 10108861,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6240744,
     "sourceId": 10115042,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6240765,
     "sourceId": 10115072,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6240772,
     "sourceId": 10115082,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
